{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPeb89mAP19rOWdMlT9udVM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine. \n","The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.\n","\n","\n","\n","Problem statement: predicting turbine energy yield (TEY) using ambient variables as features.\n","\n","\n","\n","Attribute Information:\n","\n","The explanations of sensor measurements and their brief statistics are given below.\n","\n","Variable (Abbr.) Unit Min Max Mean\n","\n","Ambient temperature (AT) C â€“6.23 37.10 17.71\n","\n","Ambient pressure (AP) mbar 985.85 1036.56 1013.07\n","\n","Ambient humidity (AH) (%) 24.08 100.20 77.87\n","\n","Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93\n","\n","Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56\n","\n","Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43\n","\n","Turbine after temperature (TAT) C 511.04 550.61 546.16\n","\n","Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06\n","\n","Turbine energy yield (TEY) MWH 100.02 179.50 133.51\n","\n","Carbon monoxide (CO) mg/m3 0.00 44.10 2.37\n","\n","Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29"],"metadata":{"id":"EH6bPtgPVySz"}},{"cell_type":"code","source":["#IMPORTING LIBRARIES\n","import pandas as pd\n","import numpy as npd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split"],"metadata":{"id":"xWotqyk2WJtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploade=files.upload()"],"metadata":{"id":"jIsdEO-7WfKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load data\n","df = pd.read_csv('gas_turbines.csv.crdownload')\n","df.head()"],"metadata":{"id":"bor_jkmSWpiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"bP32CoHIW2A5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"ZnAK8LIZW-lZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"BjHPxn7aXDsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"lQURG7NqYVPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isna().sum()"],"metadata":{"id":"RLvDWo5tXq41"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1=df.dropna(axis=0)"],"metadata":{"id":"DkEblKEeZfI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1"],"metadata":{"id":"eA_hGjBKZ8FN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.isna().sum()"],"metadata":{"id":"zDceN7yFaB14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.describe()"],"metadata":{"id":"tM0WAKxYXIXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.dtypes"],"metadata":{"id":"IV_ZK6-tXMYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check for duplicate values\n","df1[df1.duplicated()].shape"],"metadata":{"id":"sTkSI5jhaPUU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Visualisation**"],"metadata":{"id":"ROJnntcMapG2"}},{"cell_type":"code","source":["#Target variable\n","plt.title('Distplot for TEY', fontsize=17, y = 1.01)\n","sns.distplot(df1['TEY'])"],"metadata":{"id":"F9LPMKcLauqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for AT', fontsize=17, y = 1.01)\n","sns.distplot(df1['AT'])"],"metadata":{"id":"Ug7BSTVIa0WA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for AP', fontsize=17, y = 1.01)\n","sns.distplot(df1['AP'])"],"metadata":{"id":"iIuG5sOOa5qE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for AH', fontsize=17, y = 1.01)\n","sns.distplot(df1['AH'])\n","     "],"metadata":{"id":"wemMLdiRa-Ms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for AFDP', fontsize=17, y = 1.01)\n","sns.distplot(df1['AFDP'])\n","     "],"metadata":{"id":"1bgYjK_9bDmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.title('Distplot for GTEP', fontsize=17, y = 1.01)\n","sns.distplot(df1['GTEP'])"],"metadata":{"id":"z7lri2aubIDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for TIT', fontsize=17, y = 1.01)\n","sns.distplot(df1['TIT'])"],"metadata":{"id":"UyA2lDSEbUQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for TAT', fontsize=17, y = 1.01)\n","sns.distplot(df1['TAT'])\n","     "],"metadata":{"id":"rxnSjkfpbWHB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for CDP', fontsize=17, y = 1.01)\n","sns.distplot(df1['CDP'])"],"metadata":{"id":"QguU5Bj7baGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for CO', fontsize=17, y = 1.01)\n","sns.distplot(df1['CO'])"],"metadata":{"id":"EwM-Bkbpbk0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.title('Distplot for NOX', fontsize=17, y = 1.01)\n","sns.distplot(df1['NOX'])"],"metadata":{"id":"FY_EDocPbms9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check for outliers\n","fig, ax=plt.subplots(3,4, figsize=(19,6), sharex= False, sharey = False)\n","sns.boxplot(df1.TEY, ax=ax[0,0])\n","sns.boxplot(df1.AT, ax=ax[0,1])\n","sns.boxplot(df1.AP, ax=ax[0,2])\n","sns.boxplot(df1.AH, ax=ax[0,3])\n","sns.boxplot(df1.AFDP, ax=ax[1,0])\n","sns.boxplot(df1.GTEP, ax=ax[1,1])\n","sns.boxplot(df1.TIT, ax=ax[1,2])\n","sns.boxplot(df1.TAT, ax=ax[1,3])\n","sns.boxplot(df1.CDP, ax=ax[2,0])\n","sns.boxplot(df1.CO, ax=ax[2,1])\n","sns.boxplot(df1.NOX, ax=ax[2,2])\n","plt.suptitle(\"Boxplot for Continuous Variables\", fontsize= 17, y = 1.06)\n","plt.tight_layout(pad=2.0)\n","    "],"metadata":{"id":"Zycvb982bqgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"f78EtY2fbyNh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Dependency of Target variable on diff Features# New Section**"],"metadata":{"id":"Nyo25wSwb-Eu"}},{"cell_type":"code","source":["sns.pairplot(df1)"],"metadata":{"id":"giEdJ-klcDQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corr = pd.DataFrame(data = df1.corr().iloc[:,7], index=df1.columns)\n","corr = corr.sort_values(by='TEY', ascending=False)\n","corr"],"metadata":{"id":"pUvVBNr-cHVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.title(\"Correlation plot between Target variables and independent variables\", y=1.01, fontsize=18)\n","sns.barplot(x = corr.index, y = corr.TEY)"],"metadata":{"id":"Le9wbIJgdNbh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig= plt.figure(figsize=(18, 10))\n","sns.heatmap(df1.corr(), annot=True);\n","plt.xticks(rotation=45)\n","plt.title(\"Correlation Map of variables\", fontsize=19)"],"metadata":{"id":"bop8vFb0db1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ppscore\n","import ppscore as PPS\n","score = PPS.matrix(df)\n","score_s = score[score['y']=='TEY']\n","score_s.sort_values(by=\"ppscore\", ascending=False)"],"metadata":{"id":"YGDFKA_zdzSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams['figure.figsize']=(19,6)\n","sns.barplot(x='x', y='ppscore', data=score_s.sort_values(by='ppscore', ascending=False))\n","plt.title(\"PPScore of each feature with Target variable\", fontsize=17, y=1.01)\n"],"metadata":{"id":"nadyHtrLd6CQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Observation:**\n","\n","1.   From correlation matrix as well as ppscore we can clearly see that TEY is  highly dependent on 'CDP', 'GTEP', 'TIT'.\n","2.   We can drop 'AT', 'AP', 'AH' as they have very less impact on dependent variables.\n","\n"],"metadata":{"id":"Kv9YGjwvehU3"}},{"cell_type":"markdown","source":["# Check for outliers"],"metadata":{"id":"BKFShG6ffHZl"}},{"cell_type":"code","source":["#check for outliers\n","from sklearn.ensemble import IsolationForest\n","data1=df1.copy()\n","\n","#training the model\n","clf = IsolationForest(random_state=10, contamination=.001)\n","clf.fit(data1)\n","data1['anamoly'] = clf.predict(data1.iloc[:,0:11])\n","outliers = data1[data1['anamoly']==-1]\n","     "],"metadata":{"id":"DpIToyomd__U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outliers"],"metadata":{"id":"BEmtBoVGfTX0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"dHaq8KN5fkLZ"}},{"cell_type":"code","source":["df1.shape"],"metadata":{"id":"BVZxmhjkfaBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#drop the outliers\n","df1 = df1.drop(outliers.index)\n","df1.shape\n","     "],"metadata":{"id":"hW-FB2J6fszI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#reset index after dropping outliers\n","df1 = df1.reset_index()\n","df1 = df1.drop('index', axis = 1)\n","df1"],"metadata":{"id":"4O9luwdti4Em"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = df1.drop(['AT', 'AP', 'AH'], axis=1)"],"metadata":{"id":"c2W4jUEwjGq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.shape"],"metadata":{"id":"Swj-VW2DjPhf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Converting independent features into normalised and standardized data"],"metadata":{"id":"5CZ34_dFjkNe"}},{"cell_type":"code","source":["#Standardize & Normalize the data\n","norm = MinMaxScaler()\n","std = StandardScaler()\n","\n","df_norm = pd.DataFrame(norm.fit_transform(df), columns=df.columns)            #data between -3 to +3\n","df_std = pd.DataFrame(std.fit_transform(df), columns=df.columns)            #data between -1 to +1\n","     "],"metadata":{"id":"q7d4IeWGjV0r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Splitting data into target variable and independent variables"],"metadata":{"id":"2_4Uc_uxkbiv"}},{"cell_type":"code","source":["x = df1.drop('TEY', axis=1)\n","y = df1['TEY']\n","x\n","     "],"metadata":{"id":"YUeLcudFkVbS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating train and test data for model validation"],"metadata":{"id":"HfbN_o5Bl00Q"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"],"metadata":{"id":"xUznebj_l48z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"],"metadata":{"id":"ZrnLqrD_l_jc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build a Model"],"metadata":{"id":"WIRSsdmLmIpo"}},{"cell_type":"code","source":["# Importing the necessary packages\n","import tensorflow as tf\n","import keras\n","from sklearn.model_selection import GridSearchCV, KFold\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers import Dropout\n","tf.config.experimental.list_physical_devices('GPU')               #to use GPU for faster processing of model\n","     "],"metadata":{"id":"AynxZj8TmDg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create model with 2 hidden layers\n","def create_model_two_hidden_layers():\n","    model = Sequential()\n","    model.add(Dense(5, input_dim=7, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(1))\n","    \n","    adam=Adam(learning_rate=0.001)\n","    model.compile(loss='mse', optimizer=adam, metrics=['mse', 'mae', 'mape'])\n","    return model\n","\n","     "],"metadata":{"id":"ZeiJWBnnmW_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = create_model_two_hidden_layers()\n","print(\"Here is the summary of the model:\")\n","model1.summary()"],"metadata":{"id":"cxYA-So6mkpS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#create a model with 3 hidden layers\n","def create_model_three_hidden_layers():\n","    model = Sequential()\n","    model.add(Dense(32, input_dim=7, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(32, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(128, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(1))\n","    \n","    adam=Adam(learning_rate=0.01)\n","    model.compile(loss='mse', optimizer=adam, metrics=['mse', 'mae', 'mape'])\n","    return model\n"],"metadata":{"id":"waXY4_gAmv5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = create_model_three_hidden_layers()\n","print(\"Here is the summary of the model2:\")\n","model2.summary()"],"metadata":{"id":"bIb3hdNQpqTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","epochs=500\n","batch_size=50\n","\n","print(\"Here is the summary of this model:\")\n","model2.summary()\n","\n","with tf.device('/GPU:0'):\n","  model2.fit(x_train,y_train, verbose = 0,batch_size = batch_size,epochs = epochs, shuffle=True)\n"],"metadata":{"id":"W2mTP6qZrIOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Predicted values:\")\n","model2.predict(x_test[:10])"],"metadata":{"id":"W_3w-ecOrclu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Actual values')\n","y_test[:10]\n","     "],"metadata":{"id":"gHETGo8frjeq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss, mae, mse, mape = model2.evaluate(x_train, y_train)\n","print('\\n', \"Results for model 2:\", '\\n', \"Training Loss:\", loss, '\\n', \"Training Mean Absolute Error:\" , mae, '\\n', \"Training Mean Squared Error:\", mse)\n","     "],"metadata":{"id":"UCoqdbx6rnp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss, mae, mse, mape = model2.evaluate(x_test, y_test)\n","print('\\n', \"Results for model 2:\", '\\n', \"Test Loss:\", loss, '\\n', \"Test Mean Absolute Error:\" , mae, '\\n', \"Test Mean Squared Error:\", mse)\n","     "],"metadata":{"id":"-61J9wecrzKG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observations:**\n","\n","\n","*   We got pretty good results for this model.\n","Train and test errors are also quiet similar, which means our model is not overfitted or underfitted.\n","*   Still we will try to get best results by doing hyperparameter tuning.\n","\n"],"metadata":{"id":"GTpo_eU7sL0u"}},{"cell_type":"markdown","source":["# Hyperparameter Tuning to get best options for:\n","\n"," \n","\n","*   batchsize\n","\n","*  epochs\n","\n","\n","*   neurons\n","\n","*   learning rate\n","\n","*   learning rate\n","*   dropout\n","\n","\n","*   kernel initializer\n","\n","\n","*   activation function\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"nuMtNfbusa2k"}},{"cell_type":"code","source":["# Create the model\n","#get best value for batch size and epochs by hyperparameter tuning\n","model_1 = KerasRegressor(build_fn = create_model_three_hidden_layers,verbose = 0)\n","# Define the grid search parameters\n","batch_size = [30,50,70]\n","epochs = [100,300,500]\n","# Make a dictionary of the grid search parameters\n","param_grid = dict(batch_size = batch_size,epochs = epochs)\n","# Build and fit the GridSearchCV\n","grid = GridSearchCV(estimator = model_1,param_grid = param_grid,cv = KFold(),verbose = 10)\n","grid_result = grid.fit(x_train,y_train)"],"metadata":{"id":"36PuQt2Ur5AV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"L1yNUYDetkPn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get best value for learning rate and dropuout by hyperparameter tuning\n","\n","# Defining the model\n","%%time\n","def create_model_three_hidden_layers(learning_rate,dropout_rate):\n","    model = Sequential()\n","    model.add(Dense(32,input_dim = 7,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(32,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(64,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(128,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(1))\n","    \n","    adam = Adam(learning_rate = learning_rate)\n","    model.compile(loss = 'mse', optimizer = adam,metrics = ['mse', 'mae', 'mape'])\n","    return model\n","\n"],"metadata":{"id":"FC3QdVpXtpBp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the model\n","\n","model_1 = KerasRegressor(build_fn = create_model_three_hidden_layers,verbose = 0,batch_size = 70,epochs = 300)\n","\n","# Define the grid search parameters\n","\n","learning_rate = [0.001,0.01,0.1]\n","dropout_rate = [0.0,0.1,0.2]\n","\n","# Make a dictionary of the grid search parameters\n","\n","param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n","\n","# Build and fit the GridSearchCV\n","\n","grid = GridSearchCV(estimator = model_1,param_grid = param_grids,cv = KFold(),verbose = 0)\n","grid_result = grid.fit(x_train,y_train)"],"metadata":{"id":"qZ7m2KNaWyaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"aogP4YBWuHsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the model\n","#get best value for kernel initializer and activation func by hyperparameter tuning\n","%%time\n","def create_model_three_hidden_layers(activation_function,init):\n","    model = Sequential()\n","    model.add(Dense(32,input_dim = 7,kernel_initializer = init,activation = activation_function))\n","\n","    model.add(Dense(32,kernel_initializer = init,activation = activation_function))\n","    \n","    model.add(Dense(64,kernel_initializer = init,activation = activation_function))\n","    \n","    model.add(Dense(128,kernel_initializer = init,activation = activation_function))\n","    \n","    model.add(Dense(1))\n","    \n","    adam = Adam(learning_rate = 0.001)\n","    model.compile(loss = 'mse',optimizer = adam,metrics = ['mse', 'mae', 'mape'])\n","    return model\n","\n","\n"],"metadata":{"id":"jR7eWRB9_G9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the model\n","\n","model_1 = KerasRegressor(build_fn = create_model_three_hidden_layers,verbose = 0,batch_size = 70,epochs = 300)\n","\n","# Define the grid search parameters\n","activation_function = ['softmax','relu','tanh','linear']\n","init = ['uniform','normal','zero']\n","\n","# Make a dictionary of the grid search parameters\n","param_grids = dict(activation_function = activation_function,init = init)\n","\n","# Build and fit the GridSearchCV\n","\n","grid = GridSearchCV(estimator = model_1,param_grid = param_grids,cv = KFold(),verbose = 0)\n","grid_result = grid.fit(x_train,y_train)"],"metadata":{"id":"S_nJfnEzjczn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"Xu99bLFO_cYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the model\n","#get best value for neuron by hyperparameter tuning\n","%%time\n","def create_model_three_hidden_layers(neuron1,neuron2,neuron3,neuron4):\n","    model = Sequential()\n","    model.add(Dense(neuron1,input_dim = 7,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dense(neuron3,input_dim = neuron2,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dense(neuron4,input_dim = neuron3,kernel_initializer = 'uniform',activation = 'relu'))\n","    model.add(Dense(1))\n","    \n","    adam = Adam(learning_rate = 0.001)\n","    model.compile(loss = 'mse',optimizer = adam,metrics = ['mse', 'mae', 'mape'])\n","    return model\n","\n"],"metadata":{"id":"yS7oBwqd_l2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the model\n","\n","model_1= KerasRegressor(build_fn = create_model_three_hidden_layers,verbose = 0,batch_size = 70,epochs = 300)\n","\n","# Define the grid search parameters\n","\n","neuron1 = [8,16,32]\n","neuron2 = [32,64,128]\n","neuron3 = [32,64,128]\n","neuron4 = [32,64,128]\n","\n","# Make a dictionary of the grid search parameters\n","\n","param_grids = dict(neuron1 = neuron1,neuron2 = neuron2, neuron3 = neuron3, neuron4 = neuron4)\n","\n","# Build and fit the GridSearchCV\n","\n","grid = GridSearchCV(estimator = model_1,param_grid = param_grids,cv = KFold(),verbose = 0)\n","grid_result = grid.fit(x_train,y_train)\n","     "],"metadata":{"id":"oqgJLKr-oyy3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"EULUplEx_tP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a model with 3 hidden layers with best hyperparameters\n","def create_model_three_hidden_layers():\n","    model = Sequential()\n","    model.add(Dense(8, input_dim=7, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(128, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(128, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(1))\n","    \n","    adam=Adam(learning_rate=0.001)\n","    model.compile(loss='mse', optimizer=adam, metrics=['mse', 'mae', 'mape'])\n","    return model\n","     "],"metadata":{"id":"lPBdCYU5_wzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","epochs=300\n","batch_size=70\n","\n","final_model=create_model_three_hidden_layers()\n","\n","print(\"Here is the summary of our final model:\")\n","final_model.summary()\n","\n","with tf.device('/GPU:0'):\n","  final_model.fit(x_train,y_train, verbose = 0,batch_size = batch_size,epochs = epochs, shuffle=True)"],"metadata":{"id":"K4LiOOakvPvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss, mae, mse, mape = final_model.evaluate(x_train, y_train)\n","print('\\n', \"Results for final model :\", '\\n', \"Training Loss:\", loss, '\\n', \"Training Mean Absolute Error:\" , mae, '\\n', \"Training Mean Squared Error:\", mse)\n","     "],"metadata":{"id":"exowLzBAvZs9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_t, mae_t, mse_t, mape_t = final_model.evaluate(x_test, y_test)\n","print('\\n', \"Results for final model :\", '\\n', \"Test Loss:\", loss_t, '\\n', \"Test Mean Absolute Error:\" , mae_t, '\\n', \"Test Mean Squared Error:\", mse_t)\n","     \n"],"metadata":{"id":"TfH-EQJvviiF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Predicting values from Model using same dataset"],"metadata":{"id":"dErz2A6TvzoI"}},{"cell_type":"code","source":["# generating predictions for test data\n","y_predict_test = final_model.predict(x_test) "],"metadata":{"id":"_hJrl6JUvwHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating table with test price & predicted price for test\n","predictions_df = pd.DataFrame(x_test)\n","predictions_df['Actual'] = y_test\n","predictions_df['Predicted'] = y_predict_test\n","print(predictions_df.shape)\n","predictions_df.head(10)"],"metadata":{"id":"CgwM8qa1LRVw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualizing the Relationship between the Actual and Predicted Values Model Validation"],"metadata":{"id":"RsE5lED7wT7P"}},{"cell_type":"code","source":["plt.figure(figsize=(12,8))\n","plt.xlabel(\"Actual Values\")\n","plt.ylabel(\"Predicted values\")\n","plt.title(\"The Scatterplot of Relationship between Actual Values and Predictions\")\n","plt.scatter(predictions_df['Actual'], predictions_df['Predicted'])"],"metadata":{"id":"FKAtgdgUwOGf"},"execution_count":null,"outputs":[]}]}