{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPQMtCBvYtgGIzJJPV1uQKv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS"],"metadata":{"id":"Do1e_5M3EEgU"}},{"cell_type":"code","source":["#importing libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n"],"metadata":{"id":"FgG7nYTUFipM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploade=files.upload()"],"metadata":{"id":"RDLnP7_zFnJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load data\n","df = pd.read_csv('forestfires.csv')\n","df.head()\n","     "],"metadata":{"id":"wOcDLTArGYhd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"RTm9IeaHGrHX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"I1Nqwa_nGsj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"bTOB8cKBG3PT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"xtlWLHguGfq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isna().sum()"],"metadata":{"id":"KThDuoQrGm6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"vFOP_S5_HHdc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Observation:**\n","\n","1.   No missing values \n","2.  No incorrect data\n","\n","\n","\n"],"metadata":{"id":"ds5M1zbkHQyF"}},{"cell_type":"code","source":["df[df.duplicated()].shape"],"metadata":{"id":"EAx8mBLuKCDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List of Numerical Variables\n","numerical_features=[feature for feature in df.columns if df[feature].dtypes != 'O']\n","\n","print('Number of numerical variables:', len(numerical_features))\n","\n","# Visualize the numerical variables\n","df[numerical_features].head()"],"metadata":{"id":"pI6-e6OVLCIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categorical = [var for var in df.columns if df[var].dtype=='O']\n","\n","print('There are {} categorical variables\\n'.format(len(categorical)))\n","\n","print('The categorical variables are :\\n\\n', categorical)"],"metadata":{"id":"D4ZCtndpLtlY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Visualisation"],"metadata":{"id":"3Gfh22qBHsmQ"}},{"cell_type":"code","source":["#Other features with target variable\n","month_df = df.groupby(['size_category', 'month']).size().reset_index().rename(columns={0:'count'}).sort_values('count', ascending=False)\n","month_df.head(10)"],"metadata":{"id":"miQ-YZm9NJc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(x='month', y = 'count', hue='size_category', data=month_df)\n","plt.title(\"Num of fires in each month\", fontsize=17, y=1.02)"],"metadata":{"id":"IyyVoMthN-L1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tvX_c7ePODKl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observation:**\n","\n","\n","*   Aug month has seen highest number of small fires.\n","*   Whereas sep month has seen highest num of large fires.\n","*   Least num of fires occured in month of nov\n","\n","\n"],"metadata":{"id":"PzNgIPc7OHcB"}},{"cell_type":"code","source":["day_df = df.groupby(['size_category', 'day']).size().reset_index().rename(columns={0:'count'}).sort_values('count', ascending=False)\n","day_df\n","     "],"metadata":{"id":"JCfYqD-xOm1e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(x='day', y = 'count', hue='size_category', data=day_df)\n","plt.title(\"Num of fires on each day\", fontsize=17, y=1.02)"],"metadata":{"id":"YQXww1qEOuSv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observation:**\n","\n","1.   Highest num of small as well as large fires have occured on a Sunday.\n","\n","2.   Lowest num of small fires have occured on a Wednesday.\n","3.   Lowest num of large fires have occured on a Wednesday and Thursday.\n","\n","\n"],"metadata":{"id":"Ny2a-rfRO-in"}},{"cell_type":"code","source":[],"metadata":{"id":"nCiVEdE_Oz0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labelencoder = LabelEncoder()\n","df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:,-1])\n","df['size_category']       "],"metadata":{"id":"Fc0cS6hCPmbX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rain_df = df.groupby(['size_category', 'rain']).size().reset_index().rename(columns={0:'count'}).sort_values('count', ascending=False)\n","rain_df"],"metadata":{"id":"-fjLLY_nPoVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(x='rain', y='count', hue='size_category', data=rain_df)\n","plt.title(\"Rainfall level in diff category of forest\", y=1.02, fontsize=17)\n","     "],"metadata":{"id":"_v04uK46PtX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check for outliers\n","fig, ax=plt.subplots(2,4, figsize=(19,6), sharex= False, sharey = False)\n","sns.boxplot(df.FFMC, ax=ax[0,0])\n","sns.boxplot(df.DMC, ax=ax[0,1])\n","sns.boxplot(df.DC, ax=ax[0,2])\n","sns.boxplot(df.temp, ax=ax[0,3])\n","sns.boxplot(df.wind, ax=ax[1,0])\n","sns.boxplot(df.ISI, ax=ax[1,1])\n","sns.boxplot(df.RH, ax=ax[1,2])\n","plt.suptitle(\"Boxplot for Continuous Variables\", fontsize= 17, y = 1.06)\n","plt.tight_layout(pad=2.0)"],"metadata":{"id":"5UzgcT4NPxqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Let ustry to treat our outliers by log tranformations\n","fig, ax=plt.subplots(2,4, figsize=(19,6), sharex= False, sharey = False)\n","sns.boxplot(np.log(df.FFMC), ax=ax[0,0])\n","sns.boxplot(np.log(df.DMC), ax=ax[0,1])\n","sns.boxplot(np.log(df.DC), ax=ax[0,2])\n","sns.boxplot(np.log(df.temp), ax=ax[0,3])\n","sns.boxplot(np.log(df.wind), ax=ax[1,0])\n","sns.boxplot(np.log(df.ISI), ax=ax[1,1])\n","sns.boxplot(np.log(df.RH), ax=ax[1,2])\n","plt.suptitle(\"Log Transformation on Continuous Variables\", fontsize= 17, y = 1.06)\n","plt.tight_layout(pad=2.0)"],"metadata":{"id":"kEnwrt5oP6we"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Let ustry to treat our outliers by sqrt tranformations\n","fig, ax=plt.subplots(2,4, figsize=(19,6), sharex= False, sharey = False)\n","sns.boxplot(np.sqrt(df.FFMC), ax=ax[0,0])\n","sns.boxplot(np.sqrt(df.DMC), ax=ax[0,1])\n","sns.boxplot(np.sqrt(df.DC), ax=ax[0,2])\n","sns.boxplot(np.sqrt(df.temp), ax=ax[0,3])\n","sns.boxplot(np.sqrt(df.wind), ax=ax[1,0])\n","sns.boxplot(np.sqrt(df.ISI), ax=ax[1,1])\n","sns.boxplot(np.sqrt(df.RH), ax=ax[1,2])\n","plt.suptitle(\"Sqrt Transformation on Continuous Variables\", fontsize= 17, y = 1.06)\n","plt.tight_layout(pad=2.0)\n","     "],"metadata":{"id":"x2exnjEnQBnZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["None of the helpful to treat outliers in any of the features."],"metadata":{"id":"Aj7X9iZfQlob"}},{"cell_type":"markdown","source":["# Dependency of Target variable on diff Features"],"metadata":{"id":"2no-LLncRce3"}},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"8TyL44PtQK21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#to get correlation of target variable with numerical columns\n","df1 = df.drop(['month','day','dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n","       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n","       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n","       'monthoct', 'monthsep'], axis=1)\n","df1.head()"],"metadata":{"id":"s3rd9OyVRlcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corr = pd.DataFrame(data = df1.corr().iloc[:,-1], index=df1.columns)\n","corr"],"metadata":{"id":"FjbsENuKRqhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig= plt.figure(figsize=(18, 8))\n","sns.heatmap(df1.corr(), annot=True);\n","plt.xticks(rotation=45)\n","plt.title(\"Correlation Map of Numerical variables\", fontsize=19)"],"metadata":{"id":"zcSaJoCRRxg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.pairplot(df1)\n","plt.suptitle(\"Pairplot for all numerical variables\", y = 1.01, fontsize=17)\n","     "],"metadata":{"id":"TK6E-JMZR8xs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"NXcuXk_-SXq7"}},{"cell_type":"code","source":["#drop the unnecessary columns\n","df.drop(['month', 'day', 'monthjan', 'daymon'], axis=1, inplace=True)"],"metadata":{"id":"2-oshABfSc23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.set_option(\"display.max_columns\", 27)\n","df.head()\n","     "],"metadata":{"id":"Y6HwmE_EShYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check for outliers\n","from sklearn.ensemble import IsolationForest\n","data1=df.copy()\n","\n","#training the model\n","clf = IsolationForest(random_state=10, contamination=.01)\n","clf.fit(data1)\n","data1['anamoly'] = clf.predict(data1.iloc[:,0:27])\n","outliers = data1[data1['anamoly']==-1]"],"metadata":{"id":"sXQAvdxASmMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outliers"],"metadata":{"id":"2-N47LujSrz0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["outliers dataset gives the outliers in our data, and we need to remove these to improve our model"],"metadata":{"id":"EHzZdEo1S17-"}},{"cell_type":"code","source":["outliers.index"],"metadata":{"id":"6gs0Df2BPog4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Splitting data into target variable and independent variables"],"metadata":{"id":"t45bPQkITG3P"}},{"cell_type":"code","source":["x = df.drop('size_category', axis=1)\n","y = df['size_category']\n","     "],"metadata":{"id":"kaGjIM-CTL4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Standardize & Normalize the data\n","norm = MinMaxScaler()\n","std = StandardScaler()\n","\n","x_norm = pd.DataFrame(norm.fit_transform(x), columns=x.columns)            #data between -3 to +3\n","x_std = pd.DataFrame(std.fit_transform(x), columns=x.columns)            #data between -1 to +1\n","     "],"metadata":{"id":"D8oBZ7XrTPsv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_std.head()"],"metadata":{"id":"A_XX-JfwTX6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5H0yi8Q4TcD9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating train and test data\n"],"metadata":{"id":"H-rtixLBTfzn"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(x_std, y, test_size=0.25)\n","     \n"],"metadata":{"id":"xB81ItPGTmzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"],"metadata":{"id":"S31uDTaBTqpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2RS5zT-KTuoh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build a nueral network model"],"metadata":{"id":"6AXjXoxIT1F0"}},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"7kQDwVCPVUqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importing the necessary packages\n","import keras\n","from sklearn.model_selection import GridSearchCV, KFold\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"5aIMfvnkT9x0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Dropout\n","\n","# create model\n","def create_model():\n","    model = Sequential()\n","    model.add(Dense(12, input_dim=26, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n","    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n","    \n","    adam=Adam(learning_rate=0.01)\n","    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n","    return model"],"metadata":{"id":"zzCHB7WSUDWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the model\n","#get best value for batch size and epochs by hyperparameter tuning\n","model = KerasClassifier(build_fn = create_model,verbose = 0)\n","# Define the grid search parameters\n","batch_size = [10,20,40]\n","epochs = [10,50,100]\n","# Make a dictionary of the grid search parameters\n","param_grid = dict(batch_size = batch_size,epochs = epochs)\n","# Build and fit the GridSearchCV\n","grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n","grid_result = grid.fit(x_train,y_train)"],"metadata":{"id":"2hchpczaVgTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"faPY7UMFVsKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get best value for learning rate and dropuout by hyperparameter tuning\n","from keras.layers import Dropout\n","\n","# Defining the model\n","\n","def create_model(learning_rate,dropout_rate):\n","    model = Sequential()\n","    model.add(Dense(12,input_dim = 26,kernel_initializer = 'normal',activation = 'relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(1,activation = 'sigmoid'))\n","    \n","    adam = Adam(learning_rate = learning_rate)\n","    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n","    return model\n","\n","# Create the model\n","\n","model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 100)\n","\n","# Define the grid search parameters\n","\n","learning_rate = [0.001,0.01,0.1]\n","dropout_rate = [0.0,0.1,0.2]\n","\n","# Make a dictionary of the grid search parameters\n","\n","param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n","\n","# Build and fit the GridSearchCV\n","\n","grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n","grid_result = grid.fit(x_train,y_train)\n"],"metadata":{"id":"hsDBReDDVwK6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"qu43vKojWAhN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the model\n","#get best value for kernel initializer and activation func by hyperparameter tuning\n","\n","def create_model(activation_function,init):\n","    model = Sequential()\n","    model.add(Dense(8,input_dim = 26,kernel_initializer = init,activation = activation_function))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(4,kernel_initializer = init,activation = activation_function))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1,activation = 'sigmoid'))\n","    \n","    adam = Adam(learning_rate = 0.001)\n","    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n","    return model\n","\n","# Create the model\n","\n","model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 100)\n","\n","# Define the grid search parameters\n","activation_function = ['softmax','relu','tanh','linear']\n","init = ['uniform','normal','zero']\n","\n","# Make a dictionary of the grid search parameters\n","param_grids = dict(activation_function = activation_function,init = init)\n","\n","# Build and fit the GridSearchCV\n","\n","grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n","grid_result = grid.fit(x_train,y_train)\n"],"metadata":{"id":"NlIBFUIgWJZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))\n"],"metadata":{"id":"wfMd5P4pXz2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the model\n","#get best value for neuron by hyperparameter tuning\n","\n","def create_model(neuron1,neuron2):\n","    model = Sequential()\n","    model.add(Dense(neuron1,input_dim = 26,kernel_initializer = 'normal',activation = 'linear'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'normal',activation = 'linear'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1,activation = 'sigmoid'))\n","    \n","    adam = Adam(learning_rate = 0.001)\n","    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n","    return model\n","\n","# Create the model\n","\n","model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 100)\n","\n","# Define the grid search parameters\n","\n","neuron1 = [4,8,16]\n","neuron2 = [2,4,8]\n","\n","# Make a dictionary of the grid search parameters\n","\n","param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n","\n","# Build and fit the GridSearchCV\n","\n","grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n","grid_result = grid.fit(x_train,y_train)\n"],"metadata":{"id":"o4XIYr1uX5S-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the results\n","print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","  print('{},{} with: {}'.format(mean, stdev, param))"],"metadata":{"id":"B_vdvVVfX_da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# Defining the model\n","\n","def create_model():\n","    model = Sequential()\n","    model.add(Dense(16,input_dim = 26,kernel_initializer = 'normal',activation = 'linear'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(4,input_dim = 16,kernel_initializer = 'normal',activation = 'linear'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1,activation = 'sigmoid'))\n","    \n","    adam = Adam(learning_rate = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n","    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n","    return model\n","\n","# Create the model\n","\n","model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 100)\n","\n","# Fitting the model\n","\n","model.fit(x_train,y_train)\n","\n","# Predicting using trained model\n","\n","y_predict = model.predict(x_test)\n","\n","\n","# Printing the metrics\n","\n","print(\"Test Accuracy:\", accuracy_score(y_test,y_predict))\n","     "],"metadata":{"id":"Ll6caPGwYEfP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm_df=confusion_matrix(y_test, y_predict)\n","class_label = [\"1\", \"0\"]\n","df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)\n","df_cm"],"metadata":{"id":"yLCJFMz4YX_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_hat = model.predict(x_train)\n","print(\"Train Accuracy:\", accuracy_score(y_train, y_hat))"],"metadata":{"id":"AWgIlG0mYZx_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm_df=confusion_matrix(y_train, y_hat)\n","class_label = [\"1\", \"0\"]\n","df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)"],"metadata":{"id":"9EDAyLwhYdRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cm "],"metadata":{"id":"1EsThijIlnfa"},"execution_count":null,"outputs":[]}]}